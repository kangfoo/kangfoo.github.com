<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="zh"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>kangfoo's blog</title>
  <meta name="author" content="kangfoo">
  
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="OpooPressSiteRoot" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="Generator" content="OpooPress-1.0.3"/>
  <meta name="Generated" content="2015-03-03T22:39:11+08:00"/>
  <link rel="canonical" href="/page/5/">
  <link href="/page/6/" rel="next" />
  <link href="/page/4/" rel="prev" />
  <link href="/favicon.ico" rel="icon">
  <link href="/atom.xml" rel="alternate" title="kangfoo's blog" type="application/atom+xml">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
<!--Fonts from Google"s Web font directory at http://google.com/webfonts -->

<link href="http://dn-opstatic.qbox.me/themes/default/stylesheets/fonts.css" rel="stylesheet" type="text/css">

<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic|PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

国内网站：http://dn-opstatic.qbox.me/themes/default/stylesheets/fonts.css
国际网站：http://static.opoo.org/themes/default/stylesheets/fonts.css
-->

<link type="text/css" rel="stylesheet" href="/plugins/syntax-highlighter/styles/shCoreDefault.css"/>
  <!--[if lt IE 9]><script src="/javascripts/html5shiv.js"></script><![endif]-->
</head>
<body>
  <!--[if lt IE 9]><script src="/javascripts/unsupported-browser.js"></script><![endif]-->
  <header role="banner"><hgroup>
  <h1><a href="/">kangfoo's blog</a></h1>
    <h2>工作学习笔记，生活掠影。</h2>
</hgroup>
</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
</ul>
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:http://kangfoo.u.qiniudn.com/" />
    <input class="search" type="text" name="q" results="0" placeholder="搜索"/>
  </fieldset>
</form>
<fieldset class="mobile-nav">
  <select onchange="if (this.value) { window.location.href = this.value;}">
    <option value="">导航&hellip;</option>
    <option value="/">&raquo; 首页</option>

    <option value="/category/hadoop/">&raquo; hadoop</option>
    <option value="/category/java/">&raquo; java</option>

    <option value="/archives/">&raquo; 归档</option>


    <option value="http://www.opoopress.com/">&raquo; OpooPress</option>


    <option value="/about/">&raquo; 关于</option>


  </select>
</fieldset>

<ul class="main-navigation">
<li><a href="/">首页</a></li>
<li><a href="/category/hadoop/">hadoop</a></li>
<li><a href="/category/java/">java</a></li>
<li><a href="/archives/">归档</a></li>
<li><a href="http://www.opoopress.com/" target="_blank">OpooPress</a></li>
<li><a href="/about/">关于</a></li>
</ul>
</nav>
  <div id="main">
    <div id="content">
<div class="blog-index">
    <article>
  <header>
      <h1 class="entry-title"><a href="/article/2014/01/hadoop1.x-wordcount-fen-xi/">Hadoop1.x Wordcount分析</a></h1>

      <p class="meta">
		


<time datetime="2014-01-19T17:00:00+08:00" pubdate>2014年01月19日</time>
         | <a href="/article/2014/01/hadoop1.x-wordcount-fen-xi/#disqus_thread">评论</a>
      </p>
  </header>

  <div class="entry-content"><p>hadoop mapreduce 过程粗略的分为：map, redurce(copy, sort, reduce)两个阶段。具体的工作机制还是挺复杂的，这里主要通过hadoop example jar中提供的wordcount来对hadoop mapredurce做个简单的理解。Wordcount程序输入文件类型，计算单词的频率。输出是文本文件：每行是单词和它出现的频率，用Tab键隔开。</p>
<p>Hadoop内置的计数器，</p>
<ol>
<li><p>首先确保Hadoop集群正常运行，并了解mapredurce工作时涉及到的基本的文件备配。<code>vi mapred-site.xml</code></p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;!--JobTracker的主机（或者IP）和端口。 --&gt;
&lt;value&gt;master11:9001&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;mapred.system.dir&lt;/name&gt; &lt;!--Map/Reduce框架存储系统文件的HDFS路径。--&gt;
&lt;value&gt;/home/${user.name}/env/mapreduce/system&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;!--Map/Reduce在本地文件系统下中间结果存放路径. --&gt;
&lt;value&gt;/home/${user.name}/env/mapreduce/local&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</pre></li>
<li><p>上传一个文件到hdfs文件系统</br></p>
<!--- lang:shell -->
<pre class='brush:shell'>$ ./bin/hadoop fs -mkdir /test/input
$ ./bin/hadoop fs -put ./testDir/part0 /test/input
$ ./bin/hadoop fs -lsr /
## part0 文件中的内容为：
hadoop zookeeper hbase hive
rest osgi http ftp
hadoop zookeeper
</pre></li>
<li><p>执行workcount
<code>$ ./bin/hadoop jar hadoop-examples-1.2.1.jar wordcount /test/input /test/output</code></br>日志如下</p>
<!--- lang:shell -->
<pre class='brush:shell'>14/01/19 18:23:25 INFO input.FileInputFormat: Total input paths to process : 1
## 使用 native-hadoop library
14/01/19 18:23:25 INFO util.NativeCodeLoader: Loaded the native-hadoop library
14/01/19 18:23:25 WARN snappy.LoadSnappy: Snappy native library not loaded
14/01/19 18:23:25 INFO mapred.JobClient: Running job: job_201401181723_0005
14/01/19 18:23:26 INFO mapred.JobClient:  map 0% reduce 0%
14/01/19 18:23:32 INFO mapred.JobClient:  map 100% reduce 0%
14/01/19 18:23:40 INFO mapred.JobClient:  map 100% reduce 33%
14/01/19 18:23:42 INFO mapred.JobClient:  map 100% reduce 100%
## jobid job_201401181723_0005 (job_yyyyMMddHHmm_(顺序自然数，不足4位补0，已保证磁盘文件目录顺序))
14/01/19 18:23:43 INFO mapred.JobClient: Job complete: job_201401181723_0005
## Counters 计数器
14/01/19 18:23:43 INFO mapred.JobClient: Counters: 29
## Job Counters
14/01/19 18:23:43 INFO mapred.JobClient:   Job Counters
14/01/19 18:23:43 INFO mapred.JobClient:     Launched reduce tasks=1
14/01/19 18:23:43 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=6925
14/01/19 18:23:43 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
14/01/19 18:23:43 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
14/01/19 18:23:43 INFO mapred.JobClient:     Launched map tasks=1
14/01/19 18:23:43 INFO mapred.JobClient:     Data-local map tasks=1
14/01/19 18:23:43 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=9688
## File Output Format Counters
14/01/19 18:23:43 INFO mapred.JobClient:   File Output Format Counters
14/01/19 18:23:43 INFO mapred.JobClient:     Bytes Written=63
## FileSystemCounters
14/01/19 18:23:43 INFO mapred.JobClient:   FileSystemCounters
14/01/19 18:23:43 INFO mapred.JobClient:     FILE_BYTES_READ=101
14/01/19 18:23:43 INFO mapred.JobClient:     HDFS_BYTES_READ=167
14/01/19 18:23:43 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=112312
14/01/19 18:23:43 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=63
## File Input Format Counters
14/01/19 18:23:43 INFO mapred.JobClient:   File Input Format Counters
14/01/19 18:23:43 INFO mapred.JobClient:     Bytes Read=65
## Map-Reduce Framework
14/01/19 18:23:43 INFO mapred.JobClient:   Map-Reduce Framework
14/01/19 18:23:43 INFO mapred.JobClient:     Map output materialized bytes=101
14/01/19 18:23:43 INFO mapred.JobClient:     Map input records=3
14/01/19 18:23:43 INFO mapred.JobClient:     Reduce shuffle bytes=101
14/01/19 18:23:43 INFO mapred.JobClient:     Spilled Records=16
14/01/19 18:23:43 INFO mapred.JobClient:     Map output bytes=104
14/01/19 18:23:43 INFO mapred.JobClient:     Total committed heap usage (bytes)=176230400
14/01/19 18:23:43 INFO mapred.JobClient:     CPU time spent (ms)=840
14/01/19 18:23:43 INFO mapred.JobClient:     Combine input records=10
14/01/19 18:23:43 INFO mapred.JobClient:     SPLIT_RAW_BYTES=102
14/01/19 18:23:43 INFO mapred.JobClient:     Reduce input records=8
14/01/19 18:23:43 INFO mapred.JobClient:     Reduce input groups=8
14/01/19 18:23:43 INFO mapred.JobClient:     Combine output records=8
14/01/19 18:23:43 INFO mapred.JobClient:     Physical memory (bytes) snapshot=251568128
14/01/19 18:23:43 INFO mapred.JobClient:     Reduce output records=8
14/01/19 18:23:43 INFO mapred.JobClient:     Virtual memory (bytes) snapshot=1453596672
14/01/19 18:23:43 INFO mapred.JobClient:     Map output records=10
</pre></li>
<li><p>运行之后的文件系统结构
</br>日志如下</p>
<!--- lang:shell -->
<pre class='brush:shell'>drwxr-xr-x   - hadoop supergroup          0 2014-01-19 18:23 /test
drwxr-xr-x   - hadoop supergroup          0 2014-01-19 18:23 /test/input
-rw-r--r--   2 hadoop supergroup         65 2014-01-19 18:23 /test/input/part0
drwxr-xr-x   - hadoop supergroup          0 2014-01-19 18:23 /test/output
-rw-r--r--   2 hadoop supergroup          0 2014-01-19 18:23 /test/output/_SUCCESS
drwxr-xr-x   - hadoop supergroup          0 2014-01-19 18:23 /test/output/_logs
drwxr-xr-x   - hadoop supergroup          0 2014-01-19 18:23 /test/output/_logs/history
## job 执行结果的数据文件
-rw-r--r--   2 hadoop supergroup      13647 2014-01-19 18:23 /test/output/_logs/history/job_201401181723_0005_1390127005579_hadoop_word+count
## job 配置文件
-rw-r--r--   2 hadoop supergroup      48374 2014-01-19 18:23 /test/output/_logs/history/job_201401181723_0005_conf.xml
## 只分了1个
-rw-r--r--   2 hadoop supergroup         63 2014-01-19 18:23 /test/output/part-r-00000
drwxr-xr-x   - hadoop supergroup          0 2013-12-22 14:02 /user
drwxr-xr-x   - hadoop supergroup          0 2014-01-18 23:16 /user/hadoop
</pre></li>
<li><p>查看结果。<code>$ ./bin/hadoop fs -cat /test/output/part-r-00000</code></p>
<!--- lang:text -->
<pre class='brush:text'>ftp     1
hadoop  2
hbase   1
hive    1
http    1
osgi    1
rest    1
zookeeper       2
</pre></li>
<li><p>更详细的信息可web访问 http://master11:50030/jobtracker.jsp 进行查看.</p>
</li>
</ol>
</div>
    </article>
    <article>
  <header>
      <h1 class="entry-title"><a href="/article/2014/01/hadoop1.x--ming-ling-shou-ce-lie-ju/">Hadoop1.x 命令手册列举</a></h1>

      <p class="meta">
		


<time datetime="2014-01-18T18:29:00+08:00" pubdate>2014年01月18日</time>
         | <a href="/article/2014/01/hadoop1.x--ming-ling-shou-ce-lie-ju/#disqus_thread">评论</a>
      </p>
  </header>

  <div class="entry-content"><p>hadoop命令一般分为两类:</p>
<p>用户命令</br> archive, distcp, fs, fsck, jar, job, pipes, version, CLASSNAME</p>
<p>管理命令</br> balancer, daemonlog, datanode, dfsadmin, jobtracker, namenode, secondarynamenode, tasktracker</p>
<h4>用户命令</h4>
<ol>
<li><p>fs命令,可参见 <a href="http://hadoop.apache.org/docs/r1.2.1/file_system_shell.html">file system shell</a></br></p>
<!-- lang:shell-->
<pre class='brush:shell'>## 新建一个文件夹
$ ./hadoop fs -mkdir /test
## 上传一个文件到hdfs
$ ./hadoop fs -put ./rcc /test
## 查看文件
$ ./hadoop fs -lsr /test
## 文件模式  备份个数   用户   用户组   字节大小 最后修改日期 和时间 文件或者目录的绝对路径
##-rw-r--r--   2   hadoop supergroup 2810   2014-01-18 19:20  /test/rcc
## 
## 从hdfs文件系统中复制一个文件到本地
$ ./hadoop fs -copyToLocal /test/rcc rcc.copy
## md5对比
$ md5sum rcc rcc.copy
# b9d8a383bba2dd1b2ee0ede6c5cabeae  rcc
# b9d8a383bba2dd1b2ee0ede6c5cabeae  rcc.copy
##
## 删除
$ ./hadoop fs -rmr /test
</pre></li>
<li><p>fsck命令。 可以参考文件系统的健康状态；查看一个文件所在的数据块；可以删除一个坏块；可以查找一个缺失的块。 可参见<a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_user_guide.html#fsck">fsck</a></br></p>
<!-- lang:shell-->
<pre class='brush:shell'>## 新建一个文件夹
$ ./hadoop fsck /
</pre></li>
<li><p>archive命令。 创建一个hadoop档案文件。语法：archive -archiveName NAME -p &lt;parent path> &lt;src>* &lt;dest> 可参考<a href="http://hadoop.apache.org/docs/r1.2.1/hadoop_archives.html">hadoop_archives</a></br></p>
<!-- lang:shell-->
<pre class='brush:shell'>## 创建一个归档文件
$ ./hadoop archive -archiveName archive.har -p  /test rcc
## 查看归档文件列表
$ ./hadoop dfs -lsr har:///user/hadoop/rcc/archive.har
## 查看归档文件
$ ./hadoop dfs -cat har:///user/hadoop/rcc/archive.har/rcc
</pre></li>
<li><p>distcp 并行复制。可以从 Hadoop 文件系统中复制大量数据，也可以将大量数据复制到HDFS文件系统中。它其实是个没有reducer的MapReduce作业。</p>
<!-- lang:shell-->
<pre class='brush:shell'>$ hadoop distcp hadfs://datanode1/test1 hdfs://datanode2/
## 跨 RPC 版本可使用 http 方式进行复制
$ hadoop distcp http://datanode1:50070/test1 hdfs://datanode2/
</pre><h4>管理命令</h4>
</li>
<li><p>dfsadmin</br></p>
<!-- lang:shell-->
<pre class='brush:shell'>## 报告文件系统的基本信息和统计信息
$ ./hadoop dfsadmin -report
## 安全模式维护命令
$ ./hadoop dfsadmin -safemode enter
## -safemode enter | leave | get | wait
## 不接受对名字空间的更改(只读), 不复制或删除块
## -setQuota 为每个目录 &lt;dirname&gt;设定配额&lt;quota&gt;。包括文件夹和文件名称。
$ ./hadoop dfsadmin -setQuota 2 /test
$ ./hadoop fs -put ./rcc /test
$ ./hadoop fs -put ./hadoop /test
put: org.apache.hadoop.hdfs.protocol.NSQuotaExceededException: The NameSpace quota (directories and files) of directory /test is exceeded: quota=2 file count=3
</pre></li>
<li><p>balancer命令。集群平衡工具</br></p>
<!-- lang:shell-->
<pre class='brush:shell'>##
$ ./hadoop balancer
或者
$ ./bin/./start-balancer.sh
</pre></li>
</ol>
<h5>其他未列举的命令可以参见官方文档。</h5>
<p>官方文档链接: <a href="http://hadoop.apache.org/docs/r1.2.1/commands_manual.html">hadoop1.2.1 Commands Guide</a>, <a href="http://hadoop.apache.org/docs/r1.0.4/cn/commands_manual.html">hadoop1.0.4 命令手册</a></p>
</div>
    </article>
    <article>
  <header>
      <h1 class="entry-title"><a href="/article/2013/12/build-hadoop2x-eclipse-plugin/">编译hadoop 2.x Hadoop-eclipse-plugin插件</a></h1>

      <p class="meta">
		


<time datetime="2013-12-15T00:19:00+08:00" pubdate>2013年12月15日</time>
         | <a href="/article/2013/12/build-hadoop2x-eclipse-plugin/#disqus_thread">评论</a>
      </p>
  </header>

  <div class="entry-content"><p>经过hadoop1.x的发展，编译hadoop2.x版本的eclipse插件视乎比之前要轻松的多。如果你不在意编译过程中提示的警告，那么根据<a href="https://github.com/winghc/hadoop2x-eclipse-plugin">how to build - hadoop2x-eclipse-plugin</a>文档就可一步到位。若想自己设置部分变量，可参考<a href="http://kangfoo.u.qiniudn.com/article/2013/12/hadoop-eclipse-plugin-1.2.1/">编译hadoop 1.2.1 Hadoop-eclipse-plugin插件</a>。当然有问题及时和开发社区联系你会收到意想不到的收获.</p>
<p><a href="https://github.com/winghc/hadoop2x-eclipse-plugin/issues">issuce</a>站点.</p>
<h4>主要步骤</h4>
<ul>
<li>介质准备</li>
<li>执行</li>
<li>安装验证</li>
</ul>
<h4>具体操作</h4>
<ol>
<li><p>设置语言环境</p>
<!-- lang:shell-->
<pre class='brush:shell'>$ export LC_ALL=en
</pre></li>
<li><p>检查ANT_HOME,JAVA_HOME</p>
</li>
<li><p>下载hadoop2x-eclipse-plugin</br>
目前hadoop2的eclipse-plugins源代码由github脱管，下载地址<a href="https://github.com/winghc/hadoop2x-eclipse-plugin">how to build - hadoop2x-eclipse-plugin</a> 右侧的 &ldquo;Download ZIP&rdquo; 或者 克隆到桌面. 当然你也可以fork到你自己的帐户下,在使用git clone。</p>
</li>
<li><p>执行</p>
<!-- lang:shell-->
<pre class='brush:shell'>$ cd src/contrib/eclipse-plugin
$ ant jar -Dversion=2.2.0 -Declipse.home=/opt/eclipse -Dhadoop.home=/usr/share/hadoop
</pre><p>将上述java system property eclipse.home 和 hadoop.home 设置成你自己的环境路径。 执行上述命令可能很快或者很慢。请耐心等待。主要慢的target:ivy-download，ivy-resolve-common。最后jar生成在
<code>$root/build/contrib/eclipse-plugin/hadoop-eclipse-plugin-2.2.0.jar</code>路径下。</p>
</li>
<li><p>安装验证</br>
将生成好的jar,复制到<code>${eclipse.home}/plugins</code>目录下。启动eclipse，新建Map/Reduce Project,配置hadoop location.验证插件完全分布式的插件配置截图和core-site.xml端口配置。</p>
</li>
<li><p>效果图</br>
使用插件访问本地的伪分布式hadoop环境。查看文件texst1.txt和test2.txt同使用命令 hadoop dfs -ls /in 效果相同。
<img src="http://zhaomingtai.u.qiniudn.com/hadoop2x-eclipse-plugin-success.jpg" alt="image" /></p>
</li>
<li><p>已编译的插件
<a href="http://pan.baidu.com/s/1bngnciN">hadoop-eclipse-plugin-2.2.0.jar</a></p>
</li>
<li><p>备注</br>
目前我在使用这个版本的插件时发现还时挺不稳定的。发现了两个缺陷。我的环境为：Java HotSpot&trade; 64-Bit Server VM、 eclipse-standard-kepler-SR1-macosx-cocoa、 hadoop2.2.0。</p>
</li>
</ol>
<p>缺陷:</p>
<ul>
<li>Editor could not be initalized.</li>
<li>NullPointException</li>
</ul>
<p>截图如下：
<img src="http://zhaomingtai.u.qiniudn.com/hadoop2x-eclipse-plugin-exeception.jpg" alt="image" /></p>
</div>
    </article>
    <article>
  <header>
      <h1 class="entry-title"><a href="/article/2013/12/xu-ni-ji-an-zhuang-hadoop-wan-quan-fen-bu-shi/">在oracle Virtual Box 虚拟机中搭建hadoop1.2.1完全分布式环境</a></h1>

      <p class="meta">
		


<time datetime="2013-12-10T17:32:00+08:00" pubdate>2013年12月10日</time>
         | <a href="/article/2013/12/xu-ni-ji-an-zhuang-hadoop-wan-quan-fen-bu-shi/#disqus_thread">评论</a>
      </p>
  </header>

  <div class="entry-content"><h2>一、初衷</h2>
<p>对于学习 Hadoop 的我来讲，没有足够的硬件设备，但又想安装完全分布式的Hadoop，一个 master 两个 slave。手上就一台能联网的笔记本，那就使用 oracle vitual box 进行环境搭建吧。环境搭建的效果为：在虚拟机中虚拟3台 centos6.4 64 位系统，每台都配置双网卡 NAT,host-only 模式。在宿主机器上安装 eclipse 进行 Hadoop 开发。</p>
<p>Hadoop 环境搭建很大部分是在准备操作系统。具体如何搭建 Hadoop 其实就像解压缩普通的 tar 类似。然后再适当的配置 Hadoop 的 dfs,mapredurce 相关的配置，调整操作系统就可以开始着手学习 Hadoop了。</p>
<h2>二、拓补图</h2>
<p>图片制作中… …</p>
<ul>
<li>master11:192.168.56.11</li>
<li>slave12:192.168.56.12</li>
<li>slave14:192.168.56.14</li>
</ul>
<h2>三、介质准备</h2>
<ul>
<li>虚拟机 <a href="http://dlc.sun.com.edgesuite.net/virtualbox/4.2.18/VirtualBox-4.2.18-88780-OSX.dmg">oracle virtual box Mac</a></li>
<li>操作系统镜像 <a href="http://mirrors.163.com/centos/6.4/isos/x86_64/CentOS-6.4-x86_64-minimal.iso">centos 6.4 64位 网易镜像</a></li>
<li>java <a href="http://download.oracle.com/otn-pub/java/jdk/7u45-b18/jdk-7u45-linux-x64.rpm?AuthParam=1386411925_f85a151e16f1c54da8a0451e59270b4a">jdk-7u45-linux-x64.rpm</a> 或者 <a href="http://cd.ctfs.ftn.qq.com/ftn_handler/5b6bcdbb17aada3096f04db2183249eba3560a4b273bcad2993899a61afc06b5803fbcc0a64f564c0c295f339092089fcae828c2f76fccbb07e55ff3e96905c8/jdk-6u45-linux-x64-rpm.bin">jdk-6u45-linux-x64-rpm.bin</a></li>
<li>hadoop1.x <a href="http://apache.fayea.com/apache-mirror/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz">hadoop1.2.1</a></li>
<li>eclipse <a href="http://mirrors.yun-idc.com/eclipse//technology/epp/downloads/release/kepler/R/eclipse-standard-kepler-R-macosx-cocoa-x86_64.tar.gz">eclipse mac版64位</a></li>
</ul>
<p><strong>其他版本可到相关官方网站根据需要自行下载</strong></p>
<h2>四、虚拟机和基础环境搭建</h2>
<p>这里主要操作有：安装一个新的oracle virtual box，并先安装一个centos6.4 的64位的操作系统。配置操作系统双网卡、修改机器名为master11、新建hadoop用户组和hadoop用户、配置sudo权限、安装配置java环境、同步系统时间、关闭防火墙。其中有些步骤需要重启操作系统后成效，建议一切都配置后再重启并再次验证是否生效，并开始克隆两个DataNode节点服务器slave12\slave14。</p>
<h3>4.1 安装虚拟机</h3>
<p>可参见官方文档安装oracle virtual box</p>
<h3>4.2 在虚拟机里安装centos6.4</h3>
<p>此处使用的是mini版的centos6.4 64位网易提供的镜像。在安装中内存调整大于等于1g，默认为视图安装界面，小于1g则为命令行终端安装方式。可更具实际情况调整虚拟机资源分配。此处为内存1g,存储20g.网络NAT模式。</p>
<p>具体可参见<a href="http://www.jb51.net/os/78318.html">centos安装</a></p>
<h3>4.3 配置双网卡</h3>
<p>使用自己的笔记本经常遇到的问题就是在不同的网络下ip是不一样的。那么我们在学习hadoop的时候岂不是要经常修改这些ip呢。索性就直接弄个host-only模式的让oracle virtual box提供一个虚拟的网关。具体步骤：</p>
<ol>
<li><p>先关闭计算机 sudo poweroff</p>
</li>
<li><p>打开virtualbox主界面,依次点击屏幕左上角virtualbox->偏好设置->网络->点击右侧添加图标添加一个Host-Only网络vboxnet0,再设置参数值<pre>
主机虚拟网络界面（A）
IPv4地址（I）：192.168.56.1
IPv4网络掩码（M）：255.255.255.0
IPv6地址（P）：空
IPv6网络掩码长度（L）：0</pre><pre>
DHCP服务器（D）
选择启动服务器
服务器地址(r):192.168.56.100
服务器网络掩码(M):255.255.255.0
最小地址(L):192.168.56.254
最大地址(U):192.168.56.254
</pre>
截图：<img src="http://zhaomingtai.u.qiniudn.com/nat-host-only.jpg" alt="image" /></p>
</li>
<li><p>配置网卡1。选中你刚新建的虚拟机，右键设置->网络->网卡1->点击启动网络连接（E）<pre>
连接方式（A）:仅主机（Host-Only）适配器
界面名称（N）:vboxnet0(此处需要注意，如果没有进行步骤1那么这里可能无法选择，整个设置流程会提示有错误而无法继续)
高级
控制芯片（T）:xxx
混杂模式（P）:拒绝
MAC地址（M）:系统随机即可
接入网线（C）：选中
</pre></p>
</li>
<li><p>配置网卡2。点击网卡2->点击启动网络连接（E） <pre>
连接方式（A）:网络地址装换(NAT)
界面名称（N）:
高级(d)
控制芯片（T）:xxx
混杂模式（P）:拒绝
MAC地址（M）:系统随机即可
接入网线（C）：选中
</pre></p>
</li>
<li><p>配置网络。启动操作系统，使用root用户进行网络配置。</p>
<!--- lang:shell -->
<pre class='brush:shell'>cd /etc/sysconfig/network-scripts/
cp ifcfg-eth0 ifcfg-eth1
</pre><p>配置ifcfg-eth0,ifcfg-eth1两个文件与virtual box 中的网卡mac值一一对应, <code>ONBOOT=yes</code>开机启动。并将ifcfg-eth1中的网卡名称eth0改为eth1,再重启网路服务。</p>
<!--- lang:shell -->
<pre class='brush:shell'>service network start
</pre><p>其中eth0的网关信息比较多，需要根据情况具体配置。如，这里使用eth0为host-only模式，eth1为nat模式,eth0为固定ip，eth1为开机自动获取ip。可参考如下：</p>
<pre>
[root@master11 network-scripts]# cat ifcfg-eth0
DEVICE=eth0
HWADDR=08:00:27:55:99:EA（必须和virtual box 中的mac地址一致）
TYPE=Ethernet
UUID=dc6511c2-b5bb-4ccc-9775-84679a726db3（没有可不填）
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=static
NETMASK=255.255.255.0
BROADCAST=192.168.56.255
IPADDR=192.168.56.11</pre><pre>
<p>[root@master11 network-scripts]# cat ifcfg-eth1
DEVICE=eth1
HWADDR=08:00:27:13:36:C3
TYPE=Ethernet
UUID=b8f8485e-b731-4b64-8363-418dbe34880d
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=dhcp
</pre></p>
</li>
</ol>
<h3>4.4 检查机器名称</h3>
<p>检查机器名称。修改后，重启生效。</p>
<!--- lang:shell -->
<pre class='brush:shell'>   cat /etc/sysconfig/network
</pre><p>这里期望得机器名称信息是：</p>
<pre>
 NETWORKING=yes
 HOSTNAME=master11
</pre>
<h3>4.5 建立hadoop用户组和用户</h3>
<p>新建hadoop用户组和用户(以下步骤如无特殊说明默认皆使用hadoop)</p>
<!--- lang:shell -->
<pre class='brush:shell'>groupadd hadoop
useradd hadoop -g hadoop
passwd hadoop
</pre><h3>4.6 配置sudo权限</h3>
<p>CentOS普通用户增加sudo权限的简单配置<br />
查看sudo是否安装:</p>
<!--- lang:shell -->
<pre class='brush:shell'>rpm -qa|grep sudo
</pre><p>修改/etc/sudoers文件，修改命令必须为visudo才行</p>
<!--- lang:shell -->
<pre class='brush:shell'>visudo -f /etc/sudoers
</pre><p>在root ALL=(ALL) ALL 之后增加</p>
<!--- lang:shell -->
<pre class='brush:shell'>hadoop ALL=(ALL) ALL
Defaults:hadoop timestamp_timeout=-1,runaspw
</pre><pre>
增加普通账户hadoop的sudo权限
timestamp_timeout=-1 只需验证一次密码，以后系统自动记忆
runaspw  需要root密码，如果不加默认是要输入普通账户的密码</pre>
<p>修改普通用户的.bash_profile文件(vi /home/hadoop/.bash_profile)，在PATH变量中增加
<code>/sbin:/usr/sbin:/usr/local/sbin:/usr/kerberos/sbin</code></p>
<h3>4.7 安装java</h3>
<p>使用hadoop用户<code>sudo rpm -ivh jdk-7-linux-x64.rpm</code>进行安装jdk7。
配置环境变量参考<a href="http://www.cnblogs.com/zhoulf/archive/2013/02/04/2891608.html">CentOS-6.3安装配置JDK-7</a></p>
<h3>4.8 同步服务</h3>
<p>安装时间同步服务<code>sudo yum install -y ntp</code>
设置同步服务器 <code>sudo ntpdate us.pool.ntp.org</code></p>
<h3>4.9 关闭防火墙</h3>
<p>hadoop使用的端口太多了，图省事，关掉。<code>chkconfig iptables off</code>。需要重启。</p>
<h3>4.10 克隆</h3>
<p>使用虚拟机进行克隆2个datanode节点。配置网卡（参见第五步）。配置主机名（参见第六步）。配置hosts,最好也包括宿主机（<code>sudo vi /etc/hosts</code>）</p>
<pre>
192.168.56.11 master11
192.168.56.12 slave12
192.168.56.14 slave14
</pre>
<p>同步时间</p>
<!--- lang:shell -->
<pre class='brush:shell'>sudo ntpdate us.pool.ntp.org
</pre><p>重启服务<code>service network start</code>。可能出现错误参见<a href="http://blog.sina.com.cn/s/blog_77126fa501018s3d.html">device eth0 does not seem to be present, delaying initialization</a></p>
<h3>4.11 配置ssh</h3>
<ol>
<li>单机ssh配置并回环测试<!--- lang:shell -->
<pre class='brush:shell'>ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa   
chmod 700 ~/.ssh
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
</pre>输入<code>ssh localhost</code>不用输入密码直接登陆，表明ssh配置成功。（若未重新权限分配，可能无法实现ssh免密码登陆的效果。浪费了我不少时间。）</li>
<li>配置master和slave间的ssh
在slave12上执行<!--- lang:shell -->
<pre class='brush:shell'>scp hadoop@master11:~/.ssh/id_dsa.pub ./master_dsa.pub
cat master_dsa.pub &gt;&gt;authorized_keys
</pre>在master上执行<code>ssh slave12</code>若，不输入密码直接登陆，配置即通过。</li>
<li>相同的步骤需要也在slave14和master11上重复一遍。</li>
</ol>
<p>机器环境确认无误后可以轻松的安装hadoop。</p>
<h2>五、hadoop1.2.1 安装与配置</h2>
<p>经过了以上步骤准备Hadoop1.2.1的环境搭建就相对容易多了。此处就仅需要解压缩安装并配置Hadoop，再验证是否正常便可大功告成。</p>
<h3>5.1 安装</h3>
<ol>
<li>重启master11,准备工作环境目录<!--- lang:shell -->
<pre class='brush:shell'>cd ~/
mkdir env
</pre></li>
<li>解压Hadoop 1.2.1 tar<!--- lang:shell -->
<pre class='brush:shell'>tar -zxvf hadoop-1.2.1.tar.gz -C ~/env/
</pre></li>
<li>建立软链接<!--- lang:shell -->
<pre class='brush:shell'>ln -s hadoop-1.2.1/ hadoop
</pre></li>
<li>配置环境变量（<code>vi ～/.bashrc</code>）<!--- lang:shell -->
<pre class='brush:shell'>export JAVA_HOME=/usr/java/jdk1.7.0_45
source ~/.bashrc
</pre></li>
<li>同步.bashrc<pre class='brush:shell'>scp ~/.bashrc hadoop@slave12:~/
scp ~/.bashrc hadoop@slave14:~/
</pre></li>
<li>创建数据文件存放路径。主要便于管理Hadoop的数据文件。<!--- lang:shell -->
<pre class='brush:shell'>cd /home/hadoop/env
mkdir data
mkdir data/tmp
mkdir data/name
mkdir data/data
chmod 755 data/data/
mkdir mapreduce
mkdir mapreduce/system
mkdir mapreduce/local
</pre>效果如下
<pre>
├── env
│   ├── data
│   │   ├── data
│   │   ├── name
│   │   └── tmp
│   ├── hadoop -> hadoop-1.2.1/
│   ├── hadoop-1.2.1
│   │   ├── bin
│   │   ├── build.xml
│   └── mapreduce
│       ├── local
│       └── system</li>
</ol>
<p></pre></p>
<h3>5.2 配置</h3>
<ol>
<li><p>配置 conf/core-site.xml
指定hdfs协议下的存储和临时目录</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property&gt;
  &lt;name&gt;fs.default.name&lt;/name&gt;
  &lt;value&gt;hdfs://master11:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;/home/${user.name}/env/data/tmp&lt;/value&gt;
&lt;/property&gt;
</pre></li>
<li><p>配置 conf/hdfs-site.xml
配置关于hdfs相关的配置。这里将原有默认复制3个副本调整为2个。学习时可根据需求适当调整。</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property&gt;
 &lt;name&gt;dfs.name.dir&lt;/name&gt;
 &lt;value&gt;/home/${user.name}/env/data/name&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;dfs.data.dir&lt;/name&gt;
 &lt;value&gt;/home/${user.name}/env/data/data&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;dfs.replication&lt;/name&gt;
  &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;dfs.web.ugi&lt;/name&gt;
 &lt;value&gt;hadoop,supergroup&lt;/value&gt;
 &lt;final&gt;true&lt;/final&gt;
 &lt;description&gt;The user account used by the web interface. Syntax: USERNAME,GROUP1,GROUP2, ……&lt;/description&gt;
&lt;/property&gt;
</pre></li>
<li><p>配置 conf/mapred-site.xml</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property&gt;
 &lt;name&gt;mapred.job.tracker&lt;/name&gt;
 &lt;value&gt;master11:9001&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;mapred.system.dir&lt;/name&gt;
 &lt;value&gt;/home/${user.name}/env/mapreduce/system&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;mapred.local.dir&lt;/name&gt;
 &lt;value&gt;/home/${user.name}/env/mapreduce/local&lt;/value&gt;
&lt;/property&gt;
</pre></li>
<li><p>配置masters</p>
<!--- lang:shell -->
<pre class='brush:shell'>vi masters
</pre><p>写为</p>
<!--- lang:shell -->
<pre class='brush:shell'>master11
</pre></li>
<li><p>配置slaves</p>
<!--- lang:shell -->
<pre class='brush:shell'>vi slaves
</pre><p>写为</p>
<!--- lang:shell -->
<pre class='brush:shell'>slave12
slave14
</pre></li>
<li><p>同步hadoop到子节点</p>
<!--- lang:shell -->
<pre class='brush:shell'>scp -r ~/env/ hadoop@slave12:~/
scp -r ~/env/ hadoop@slave14:~/
</pre></li>
</ol>
<h3>5.3 启动hadoop</h3>
<ol>
<li><p>在主节点上格式化namenode</p>
<!--- lang:shell -->
<pre class='brush:shell'>./bin/hadoop namenode -format
</pre></li>
<li><p>在主节点上启动Hadoop</p>
<!--- lang:shell -->
<pre class='brush:shell'>./bin/start-all.sh
</pre></li>
</ol>
<h3>5.4 检查运行状态</h3>
<ol>
<li><p>通过web查看Hadoop状态</p>
<pre>
http://192.168.56.11:50030/jobtracker.jsp
http://192.168.56.11:50070/dfshealth.jsp
</pre>
</li>
<li><p>验证Hadoop mapredurce
执行<code>hadoop jar hadoop-xx-examples.jar</code> 验证jobtracker和tasktracker</p>
<!--- lang:shell -->
<pre class='brush:shell'>./bin/hadoop jar hadoop-0.16.0-examples.jar wordcount input output
</pre><p>可wordcount参考<a href="http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html">Hadoop集群（第6期）_WordCount运行详解</a></p>
</li>
</ol>
<h2>六、常见错误</h2>
<ul>
<li><p>expected: rwxr-xr-x, while actual: rwxrwxr-x
WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Invalid directory in dfs.data.dir: Incorrect permission for /home/hadoop/env/data/data, expected: rwxr-xr-x, while actual: rwxrwxr-x <br />
<strong>解决方案</strong>：chmod 755 /home/hadoop/env/data/data</p>
</li>
<li><p>节点之间不能通信
java.io.IOException: File xxx/jobtracker.info could only be replicated to 0 nodes, instead of 1 <br />
java.net.NoRouteToHostException: No route to host <br />
<strong>解决方案</strong>：关闭iptables，<code>sudo /etc/init.d/iptables stop</code></p>
</li>
<li><p>got exception trying to get groups for user webuser</p>
<pre>
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser：无此用户
     at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
     at org.apache.hadoop.util.Shell.run(Shell.java:182)
</pre>
<p><strong>解决方案</strong>：
在hdfs-site.xml文件中添加</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property&gt;
 &lt;name&gt;dfs.web.ugi&lt;/name&gt;
 &lt;value&gt;hadoop,supergroup&lt;/value&gt;
 &lt;final&gt;true&lt;/final&gt;
 &lt;description&gt;The user account used by the web interface.Syntax: USERNAME,GROUP1,GROUP2, ……
 &lt;/description&gt;
&lt;/property&gt;
</pre><p>加上这个配置。可以解决了</p>
<pre>
value  第一个为你自己搭建hadoop的用户名,第二个为用户所属组因为默认  
</pre>
<p>web访问授权是webuser用户。访问的时候。我们一般用户名不是webuser所有要覆盖掉默认的webuser</p>
</li>
</ul>
<h2>七、附录</h2>
<ul>
<li>无意中Google到的一个<a href="http://t3serv002.mit.edu:50070/dfshealth.jsp">hadoop</a></li>
<li>参考博文：<a href="http://blog.csdn.net/ab198604/article/details/8250461">hadoop学习之hadoop完全分布式集群安装</a> 图文并茂</li>
<li>参考博文：<a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop1/">用 Hadoop 进行分布式并行编程, 第 1 部分</a> 理论与实践相结合</li>
<li>参考博文：<a href="http://www.jb51.net/os/78318.html">centos安装</a></li>
</ul>
</div>
    </article>
    <article>
  <header>
      <h1 class="entry-title"><a href="/article/2013/12/hadoop-eclipse-plugin-1.2.1/">编译hadoop 1.2.1 Hadoop-eclipse-plugin插件</a></h1>

      <p class="meta">
		


<time datetime="2013-12-09T22:52:00+08:00" pubdate>2013年12月09日</time>
         | <a href="/article/2013/12/hadoop-eclipse-plugin-1.2.1/#disqus_thread">评论</a>
      </p>
  </header>

  <div class="entry-content"><p>编译hadoop1.x.x版本的eclipse插件为何如此繁琐？</p>
<p>个人理解，ant的初衷是打造一个本地化工具，而编译hadoop插件的资源间的依赖超出了这一目标。导致我们在使用ant编译的时候需要手工去修改配置。那么自然少不了设置环境变量、设置classpath、添加依赖、设置主函数、javac、jar清单文件编写、验证、部署等步骤。</p>
<p>那么我们开始动手</p>
<h4>主要步骤如下</h4>
<ul>
<li>设置环境变量</li>
<li>设置ant初始参数</li>
<li>调整java编译参数</li>
<li>设置java classpath</li>
<li>添加依赖</li>
<li>修改META-INF文件</li>
<li>编译打包、部署、验证</li>
</ul>
<h4>具体操作</h4>
<ol>
<li><p>设置语言环境</br></p>
<!-- lang:shell-->
<pre class='brush:shell'>$ export LC_ALL=en
</pre></li>
<li><p>设置ant初始参数</br>
修改build-contrib.xml文件</p>
<!--- lang:shell -->
<pre class='brush:shell'>$ cd /hadoop-1.2.1/src/contrib
$ vi build-contrib.xml
</pre><p>编辑并修改hadoop.root值为实际hadoop解压的根目录</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property name="hadoop.root" location="/Users/kangfoo-mac/study/hadoop-1.2.1"/&gt;
</pre><p>添加eclipse依赖</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property name="eclipse.home" location="/Users/kangfoo-mac/work/soft/eclipse-standard-kepler-SR1-macosx-cocoa" /&gt;
</pre><p>设置版本号</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property name="version" value="1.2.1"/&gt;
</pre></li>
<li><p>调整java编译设置</br>
启用javac.deprecation</p>
<!--- lang:shell -->
<pre class='brush:shell'>$ cd /hadoop-1.2.1/src/contrib
$ vi build-contrib.xml
</pre><p>将<br  /></p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property name="javac.deprecation" value="off"/&gt;
</pre><p>改为</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;property name="javac.deprecation" value="on"/&gt;
</pre></li>
<li><p>ant 1.8+ 版本需要额外的设置javac includeantruntime=&ldquo;on&rdquo; 参数</br></p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;!-- ====================================================== --&gt;
&lt;!-- Compile a Hadoop contrib's files                       --&gt;
&lt;!-- ====================================================== --&gt;
&lt;target name="compile" depends="init, ivy-retrieve-common" unless="skip.contrib"&gt;
&lt;echo message="contrib: ${name}"/&gt;
&lt;javac
 encoding="${build.encoding}"
 srcdir="${src.dir}"
 includes="**/*.java"
 destdir="${build.classes}"
 debug="${javac.debug}"
 deprecation="${javac.deprecation}"
 includeantruntime="on"&gt;
 &lt;classpath refid="contrib-classpath"/&gt;
&lt;/javac&gt;
&lt;/target&gt; 
</pre></li>
<li><p>修改编译hadoop插件 classpath</br></p>
<!--- lang:shell -->
<pre class='brush:shell'>$ cd hadoop-1.2.1/src/contrib/eclipse-plugin
$ vi build.xml
</pre><p>添加 文件路径 hadoop-jars</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;path id="hadoop-jars"&gt;
  &lt;fileset dir="${hadoop.root}/"&gt;
    &lt;include name="hadoop-*.jar"/&gt;
  &lt;/fileset&gt;
&lt;/path&gt;
</pre><p>将hadoop-jars 添加到classpath</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;path id="classpath"&gt;
  &lt;pathelement location="${build.classes}"/&gt;
  &lt;pathelement location="${hadoop.root}/build/classes"/&gt;
  &lt;path refid="eclipse-sdk-jars"/&gt;
  &lt;path refid="hadoop-jars"/&gt;
&lt;/path&gt; 
</pre></li>
<li><p>修改或添加额外的jar依赖</br>
因为我们根本都没有直接编译过hadoop,所以就直接使用${HADOOP_HOME}/lib下的资源.需要注意，这里将依赖jar的版本后缀去掉了。</br>
同样还是在hadoop-1.2.1/src/contrib/eclipse-plugin/build.xml文件中修改或添加</p>
<!--- lang:shell -->
<pre class='brush:shell'>$ cd hadoop-1.2.1/src/contrib/eclipse-plugin
$ vi build.xml
</pre><p>找到 <code>&lt;!-- Override jar target to specify manifest --&gt;</code> 修改target name为 jar 中的 copy file 的路径，具体如下：</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;copy file="${hadoop.root}/hadoop-core-${version}.jar" tofile="${build.dir}/lib/hadoop-core.jar" verbose="true"/&gt;
&lt;copy file="${hadoop.root}/lib/commons-cli-${commons-cli.version}.jar"  tofile="${build.dir}/lib/commons-cli.jar" verbose="true"/&gt;
&lt;copy file="${hadoop.root}/lib/commons-configuration-1.6.jar"  tofile="${build.dir}/lib/commons-configuration.jar" verbose="true"/&gt;
&lt;copy file="${hadoop.root}/lib/commons-httpclient-3.0.1.jar"  tofile="${build.dir}/lib/commons-httpclient.jar" verbose="true"/&gt;
&lt;copy file="${hadoop.root}/lib/commons-lang-2.4.jar"  tofile="${build.dir}/lib/commons-lang.jar" verbose="true"/&gt;
&lt;copy file="${hadoop.root}/lib/jackson-core-asl-1.8.8.jar"  tofile="${build.dir}/lib/jackson-core-asl.jar" verbose="true"/&gt;
&lt;copy file="${hadoop.root}/lib/jackson-mapper-asl-1.8.8.jar"  tofile="${build.dir}/lib/jackson-mapper-asl.jar" verbose="true"/&gt;
</pre></li>
<li><p>修改 jar 清单文件</p>
<!--- lang:shell -->
<pre class='brush:shell'>cd ./hadoop-1.2.1/src/contrib/eclipse-plugin/META-INF
vi MANIFEST.MF
</pre><p>找到这个文件的Bundle-ClassPath这一行，然后，修改成</p>
<!--- lang:shell -->
<pre class='brush:shell'>Bundle-ClassPath: classes/,lib/commons-cli.jar,lib/commons-httpclient.jar,lib/hadoop-core.jar,lib/jackson-mapper-asl.jar,lib/commons-configuration.jar,lib/commons-lang.jar,lib/jackson-core-asl.jar
</pre><p>请保证上述字符占用一行，或者满足osgi bundle 配置文件的换行标准语法也行的。省事就直接写成一行，搞定。</p>
</li>
<li><p>新建直接打包并部署jar到eclipse/plugin目录的target</p>
<!--- lang:shell -->
<pre class='brush:shell'>cd hadoop-1.2.1/src/contrib/eclipse-plugin
vi build.xml
</pre><p>添加target直接将编译的插件拷贝到eclipse插件目录</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;target name="deploy" depends="jar" unless="skip.contrib"&gt; 
&lt;copy file="${build.dir}/hadoop-${name}-${version}.jar" todir="${eclipse.home}/plugins" verbose="true"/&gt; &lt;/target&gt;
</pre><p>将ant默认target default=&ldquo;java"改为default=&ldquo;deploy&rdquo;</p>
<!--- lang:xml -->
<pre class='brush:xml'>&lt;project default="deploy" name="eclipse-plugin"&gt;
</pre></li>
<li><p>编译并启动eclipse验证插件</p>
<!--- lang:shell -->
<pre class='brush:shell'>ant -f ./hadoop-1.2.1/src/contrib/eclipse-plugin/build.xml
</pre><p>启动eclipse，新建Map/Reduce Project,配置hadoop location.验证插件完全分布式的插件配置截图和core-site.xml端口配置</p>
</li>
<li><p>效果图
<img src="http://zhaomingtai.u.qiniudn.com/hadoop-eclipse-plugins-1.2.1.png?token=aq6Vqqet0FuJ5-au0uAsoWmT8velHmW1zuXJ56PU:b0nXaq4z_psXKmgw0yBWCQIlw9w=:eyJTIjoiemhhb21pbmd0YWkudS5xaW5pdWRuLmNvbS9oYWRvb3AtZWNsaXBzZS1wbHVnaW5zLTEuMi4xLnBuZyIsIkUiOjEzODY3Mzg2NjB9" alt="image" /></p>
</li>
</ol>
<h4>相关源文件</h4>
<ul>
<li><a href="http://pan.baidu.com/s/1c0mW8Sg">hadoop-1.2.1/src/contrib/build-contrib.xml</a></li>
<li><a href="http://pan.baidu.com/s/1qWvvAG0">hadoop-1.2.1/src/contrib/eclipse-plugin/build.xml</a></li>
<li><a href="http://pan.baidu.com/s/1qWJclWC">hadoop-1.2.1/src/contrib/eclipse-plugin/META-INF/MANIFEST.MF</a></li>
<li><a href="http://pan.baidu.com/s/1dDoWzvF">hadoop-eclipse-plugin-1.2.1.jar</a></li>
</ul>
<p><em>在此非常感谢<a href="http://www.cnblogs.com/kinuxroot/archive/2013/05/06/linux_hadoop_eclipse_plugin.html">kinuxroot</a>这位博主的的博文参考。</em></p>
</div>
    </article>
  
  <div class="pagination">
<span class="pagebar">
<span class="nolink-page" title="第 5 页，共 6 页">5/6</span>
<a rel="full-article" href="/page/4/" title="上一页">&lt;</a>
<a rel="full-article" href="/">1</a>
<span class="nolink-page">...</span>
<a rel="full-article" href="/page/3/">3</a>
<a rel="full-article" href="/page/4/">4</a>
<span class="current-page">5</span>
<a rel="full-article" href="/page/6/">6</a>



 <a rel="full-article" href="/page/6/" title="下一页">&gt;</a>
</span>
<a class="next" href="/archives">文章目录</a>  </div>
</div>
<aside class="sidebar">
<section>
  <h1>近期文章</h1>
  <ul id="recent_posts">
  
  
      <li class="post">
        <a href="/article/2014/04/spring-batch--ru-men/">Springbatch入门</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-pipes--streaming/">Hadoop Pipes & Streaming</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-sort/">Hadoop MapReduce Sort</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-join/">Hadoop MapReduce Join</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce--ji-shu-qi/">Hadoop MapReduce 计数器</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-recordreader-zu-jian/">Hadoop MapReduce RecordReader 组件</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-partitioner--zu-jian/">Hadoop MapReduce Partitioner 组件</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-combiner--zu-jian/">Hadoop MapReduce Combiner 组件</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce--lei-xing-yu-ge-shi/">Hadoop MapReduce 类型与格式</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce--gong-zuo-ji-zhi/">Hadoop MapReduce 工作机制</a>
      </li>
  </ul>
</section>
<section>
  <h2>近期评论</h2>
 <script language="JavaScript">
  <!--
	var is_https = ('https:' == document.location.protocol);
	var rcw_script_src = (is_https ? 'https:' : 'http:') + '//kangaroo.disqus.com/recent_comments_widget.js?num_items=5&excerpt_length=100&hide_avatars=' + (is_https ? '1' : '0&avatar_size=32');
	var rcw_script = '<scr' + 'ipt type="text/javascript" src="' + rcw_script_src + '"></scr' + 'ipt>';
	document.writeln(rcw_script);
  //-->
  </script>
</section>
</aside>
    </div>
  </div>
  <footer role="contentinfo"><p>
  版权所有 &copy; 2015 - kangfoo -
  <span class="credit">Powered by <a href="http://www.opoopress.com/">OpooPress</a></span>
 
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1000232528'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s22.cnzz.com/z_stat.php%3Fid%3D1000232528%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>
</footer>
<script type="text/javascript" src="/javascripts/opoopress.min.js"></script>
<script language="JavaScript">
<!--
    window.OpooPress = new OpooPressApp({siteUrl:'http://kangfoo.u.qiniudn.com/',rootUrl:'',pageUrl:'/page/5/',refreshRelativeTimes:true,verbose:true},{});
    OpooPress.init();

    var disqus_shortname = 'kangaroo';
    OpooPress.showDisqusCommentCount();
//-->
</script>
<!-- START: Syntax Highlighter ComPress -->
<script type="text/javascript" src="/plugins/syntax-highlighter/scripts/shCore.js"></script>
<script type="text/javascript" src="/plugins/syntax-highlighter/scripts/shAutoloader.js"></script>
<script type="text/javascript">
    SyntaxHighlighter.autoloader(
        'applescript			/plugins/syntax-highlighter/scripts/shBrushAppleScript.js',
        'actionscript3 as3		/plugins/syntax-highlighter/scripts/shBrushAS3.js',
        'bash shell				/plugins/syntax-highlighter/scripts/shBrushBash.js',
        'coldfusion cf			/plugins/syntax-highlighter/scripts/shBrushColdFusion.js',
        'cpp c					/plugins/syntax-highlighter/scripts/shBrushCpp.js',
        'c# c-sharp csharp		/plugins/syntax-highlighter/scripts/shBrushCSharp.js',
        'css					/plugins/syntax-highlighter/scripts/shBrushCss.js',
        'delphi pascal pas		/plugins/syntax-highlighter/scripts/shBrushDelphi.js',
        'diff patch			    /plugins/syntax-highlighter/scripts/shBrushDiff.js',
        'erl erlang				/plugins/syntax-highlighter/scripts/shBrushErlang.js',
        'groovy					/plugins/syntax-highlighter/scripts/shBrushGroovy.js',
        'java					/plugins/syntax-highlighter/scripts/shBrushJava.js',
        'jfx javafx				/plugins/syntax-highlighter/scripts/shBrushJavaFX.js',
        'js jscript javascript	/plugins/syntax-highlighter/scripts/shBrushJScript.js',
        'perl pl				/plugins/syntax-highlighter/scripts/shBrushPerl.js',
        'php					/plugins/syntax-highlighter/scripts/shBrushPhp.js',
        'text plain				/plugins/syntax-highlighter/scripts/shBrushPlain.js',
        'powershell ps          /plugins/syntax-highlighter/scripts/shBrushPowerShell.js',
        'py python				/plugins/syntax-highlighter/scripts/shBrushPython.js',
        'ruby rails ror rb		/plugins/syntax-highlighter/scripts/shBrushRuby.js',
        'sass scss              /plugins/syntax-highlighter/scripts/shBrushSass.js',
        'scala					/plugins/syntax-highlighter/scripts/shBrushScala.js',
        'sql					/plugins/syntax-highlighter/scripts/shBrushSql.js',
        'vb vbnet				/plugins/syntax-highlighter/scripts/shBrushVb.js',
        'xml xhtml xslt html	/plugins/syntax-highlighter/scripts/shBrushXml.js'
    );
    SyntaxHighlighter.defaults['auto-links'] = false;                 
    SyntaxHighlighter.defaults['toolbar'] = false;     
    SyntaxHighlighter.defaults['tab-size'] = 4;
    SyntaxHighlighter.all();
</script>
<!-- END: Syntax Highlighter ComPress -->
</body>
</html>
