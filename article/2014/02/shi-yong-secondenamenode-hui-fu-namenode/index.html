<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="zh"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>模拟使用 SecondaryNameNode 恢复 NameNode - kangfoo's blog</title>
  <meta name="author" content="kangfoo">
  <meta name="description" content="模拟使用 SecondaryNameNode 恢复 NameNode">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="OpooPressSiteRoot" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="Generator" content="OpooPress-1.0.3"/>
  <meta name="Generated" content="2014-03-05T01:02:11+08:00"/>
  <link rel="canonical" href="/article/2014/02/shi-yong-secondenamenode-hui-fu-namenode/">
  
  
  <link href="/favicon.ico" rel="icon">
  <link href="/atom.xml" rel="alternate" title="kangfoo's blog" type="application/atom+xml">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
<!--Fonts from Google"s Web font directory at http://google.com/webfonts -->

<link href="http://dn-opstatic.qbox.me/themes/default/stylesheets/fonts.css" rel="stylesheet" type="text/css">

<!--
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic|PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

国内网站：http://dn-opstatic.qbox.me/themes/default/stylesheets/fonts.css
国际网站：http://static.opoo.org/themes/default/stylesheets/fonts.css
-->

<link type="text/css" rel="stylesheet" href="/plugins/syntax-highlighter/styles/shCoreDefault.css"/>
  <!--[if lt IE 9]><script src="/javascripts/html5shiv.js"></script><![endif]-->
</head>
<body>
  <!--[if lt IE 9]><script src="/javascripts/unsupported-browser.js"></script><![endif]-->
  <header role="banner"><hgroup>
  <h1><a href="/">kangfoo's blog</a></h1>
    <h2>工作学习笔记，生活掠影。</h2>
</hgroup>
</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
</ul>
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:http://kangfoo.u.qiniudn.com/" />
    <input class="search" type="text" name="q" results="0" placeholder="搜索"/>
  </fieldset>
</form>
<fieldset class="mobile-nav">
  <select onchange="if (this.value) { window.location.href = this.value;}">
    <option value="">导航&hellip;</option>
    <option value="/">&raquo; 首页</option>

    <option value="/category/hadoop/">&raquo; hadoop</option>
    <option value="/category/java/">&raquo; java</option>

    <option value="/archives/">&raquo; 归档</option>


    <option value="http://www.opoopress.com/">&raquo; OpooPress</option>


    <option value="/about/">&raquo; 关于</option>


  </select>
</fieldset>

<ul class="main-navigation">
<li><a href="/">首页</a></li>
<li><a href="/category/hadoop/">hadoop</a></li>
<li><a href="/category/java/">java</a></li>
<li><a href="/archives/">归档</a></li>
<li><a href="http://www.opoopress.com/" target="_blank">OpooPress</a></li>
<li><a href="/about/">关于</a></li>
</ul>
</nav>
  <div id="main">
    <div id="content">
<div>
<article class="hentry" role="article">
  <header>
      <h1 class="entry-title">模拟使用 SecondaryNameNode 恢复 NameNode</h1>

      <p class="meta">
		


<time datetime="2014-02-26T00:50:00+08:00" pubdate>2014年02月26日</time>
         | <a href="#disqus_thread">评论</a>
      </p>
  </header>

  <div class="entry-content"><h2>SecondaryNameNode</h2>
<p>在试验前先了解下什么是 SecondaryNameNode、它的原理、检查点等知识点。再依次从开始配置 SecondaryNameNode 检查点、准备测试环境、模拟正常的 NameNode 故障，并手动启动 NameNode 并从 SecondaryNameNode 中恢复 fsimage。</p>
<p><strong>注</strong>：此试验思路主要借鉴于<a href="http://new.osforce.cn/?mu=20140227220525KZol8ENMYdFQ6SjMveU26nEZ">开源力量</a>的<a href="http://new.osforce.cn/course/101?mc101=20140301233857au7XG16o9ukfev1pmFCOfv2s">LouisT 老师 Hadoop Development 课程</a>中的SecondaryNameNode章节。</p>
<h3>作用</h3>
<p>主要是为了解决namenode单点故障。不是 namenode 的备份。它周期性的合并 fsimage ( namenode 的镜像)和 editslog（或者 edits——所有对 fsimage 镜像文件操作的步骤）,并推送给 namenode 以辅助恢复namenode。</p>
<p>SecondaryNameNode 定期合并 fsimage 和 edits 日志，将 edits 日志文件大小控制在一个限度下。因为内存需求和 NameNode 在一个数量级上，所以通常 SecondaryNameNode 和 NameNode 运行在不同的机器上。SecondaryNameNode 通过bin/start-dfs.sh 在 conf/masters 中指定的节点上启动。</p>
<p>在hadoop 2.x 中它的作用可以被两个节点替换：checkpoint node(于 SecondaryNameNode 作用相同), backup node( namenode 的完全备份)</p>
<h3>原理（具体可参见《Hadoop权威指南》第10章 管理Hadoop）</h3>
<p>edits 文件纪录了所有对 fsimage 镜像文件的写操作的步骤。文件系统客户端执行写操作时，这些操作首先会被记录到 edits 文件中。Nodename 在内存中维护文件系统的元数据；当 edits 被修改时，相关元数据也同步更新。内存中的元数据可支持客户端的读请求。</p>
<p>在每次执行写操作之后，且在向客户端发送成功代码之前，edits 编辑日志都需要更新和同步。当 namedone 向多个目录写数据时，只有在所有写操作执行完毕之后方可返回成功代码，以保证任何操作都不会因为机器故障而丢失。</p>
<p>fsimage 文件是文件系统元数据的一个永久检查点。它包含文件系统中的所有目录和文件 inode 的序列化谢谢。每个 inode 都是一个文件或目录的元数据的内部描述方式。对于文件来说，包含的信息有“复制级别”、修改时间、访问时间、访问许可、块大小、组成一个文件的块等；对于目录来说，包含的信息有修改时间、访问许可和配额元数据等信息。</p>
<p>fsimage 是一个大型文件，频繁执行写操作，会使系统运行极慢。并非每一写操作都会更新到 fsimage 文件。
SecondaryNameNode 辅助 namenode，为 namenode 内存中的文件系统元数据创建检查点，并最终合并并更新 fsimage 镜像和减小 edits 文件。</p>
<h3>SecondaryNameNode 的检查点</h3>
<p>SecondaryNameNode 进程启动是由两个配置参数控制的。</p>
<ul>
<li>fs.checkpoint.period，指定连续两次检查点的最大时间间隔， 默认值是1小时。</li>
<li>fs.checkpoint.size 定义了 edits 日志文件的最大值，一旦超过这个值会导致强制执行检查点（即使没到检查点的最大时间间隔）。默认值是64MB。</li>
</ul>
<h3>SecondaryNameNode 检查点的具体步骤</h3>
<p><img src="http://zhaomingtai.u.qiniudn.com/snn.png" alt="image" /></p>
<ol>
<li>SecondaryNameNode 请求主 namenode 停止使用 edits 文件，暂时将新的操作记录到 edits.new 文件中；</li>
<li>SecondaryNameNode 以 http get 复制 主 namenode 中的 fsimage, edits 文件；</li>
<li>SecondaryNameNode 将 fsimage 载入到内存，并逐一执行 edits 文件中的操作，创建新的fsimage.ckpt 文件；</li>
<li>SecondaryNameNode 以 http post 方式将新的fsimage.ckp 复制到主namenode.</li>
<li>主 namenode 将 fsimage 文件替换为 fsimage.ckpt，同时将 edits.new 文件重命名为 edits。并更新 fstime 文件来记录下次检查点时间。</li>
</ol>
<p>SecondaryNameNode 保存最新检查点的目录与 NameNode 的目录结构相同。 所以 NameNode 可以在需要的时候读取 SecondaryNameNode上的检查点镜像。</p>
<h3>模拟 NameNode 故障以从 SecondaryNameNode 恢复</h3>
<p>场景假设：如果NameNode上除了最新的检查点以外，所有的其他的历史镜像和 edits 文件都丢失了，NameNode 可以引入这个最新的检查点以恢复。具体模拟步骤如下：</p>
<ol>
<li>在配置参数 dfs.name.dir 指定的位置建立一个空文件夹；</li>
<li>把检查点目录的位置赋值给配置参数 fs.checkpoint.dir；</li>
<li>启动NameNode，并加上-importCheckpoint。</li>
</ol>
<p>NameNode 会从 fs.checkpoint.dir 目录读取检查点，并把它保存在 dfs.name.dir 目录下。 如果 dfs.name.dir 目录下有合法的镜像文件，NameNode 会启动失败。 NameNode 会检查fs.checkpoint.dir 目录下镜像文件的一致性，但是不会去改动它。</p>
<h3>试验从 SecondaryNameNode 中备份恢复 NameNode</h3>
<p><strong>注意</strong>：此步骤执行并不能将原的数据文件系统从物理磁盘上移除，同样也不能在新格式化的 namenode 中查看旧的文件系统文件。请确定无误再试验。</p>
<h4>试验知识准备</h4>
<p>命令的使用方法请参考 <a href="http://hadoop.apache.org/docs/r1.2.1/commands_manual.html#secondarynamenode">SecondaryNameNode 命令</a>。在试验前，可先了解些 hadoop 的默认配置
<a href="http://hadoop.apache.org/docs/r1.1.2/core-default.html">core-site.xml-default</a>,
<a href="http://hadoop.apache.org/docs/r1.1.2/hdfs-default.html">hdfs-site.xml-default</a>,
<a href="http://hadoop.apache.org/docs/r1.1.2/mapred-default.html">mapred-site.xml-default</a></p>
<p>SecondarynameNode 相关属性描述：</p>
<pre>
属性：fs.checkpoint.dir     
值：${hadoop.tmp.dir}/dfs/namesecondary
描述：Determines where on the local filesystem the DFS secondary name node should store the temporary images to merge. If this is a comma-delimited list of directories then the image is replicated in all of the directories for redundancy.
fs.checkpoint.edits.dir

属性：${fs.checkpoint.dir}     
值：Determines where on the local filesystem the DFS secondary name node should 
描述：store the temporary edits to merge. If this is a comma-delimited list of directoires then teh edits is replicated in all of the directoires for redundancy. Default value is same as fs.checkpoint.dir

属性：fs.checkpoint.period  
值：3600   
描述：The number of seconds between two periodic checkpoints.

属性：fs.checkpoint.size    
值：67108864   
描述：The size of the current edit log (in bytes) that triggers a periodic checkpoint even if the fs.checkpoint.period hasn't expired.
</pre>
<h4>试验环境配置</h4>
<ol>
<li><p>首先修改 core-site.xml 文件中的配置，主要是调小了 checkpoint 的周期并指定 SSN 的目录。</p>
<pre class='brush:xml'>&lt;property&gt;
&lt;name&gt;fs.checkpoint.period&lt;/name&gt;
&lt;value&gt;120&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;fs.checkpoint.dir&lt;/name&gt;
&lt;value&gt;/home/${user.name}/env/data/snn&lt;/value&gt;
&lt;/property&gt;
</pre><p><code>vi hdfs-site.xml</code> 查看 NameNode 数据文件存储路径</p>
<pre class='brush:xml'>&lt;property&gt;
 &lt;name&gt;dfs.name.dir&lt;/name&gt;
 &lt;value&gt;/home/${user.name}/env/data/name&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;dfs.data.dir&lt;/name&gt;
 &lt;value&gt;/home/${user.name}/env/data/data&lt;/value&gt;
&lt;/property&gt;
</pre></li>
<li><p>再次，format namenode 。 <code>./bin/hadoop namenode -format</code>。查看当前的 master namenode namespaceID <code>cat ./name/current/VERSION</code></p>
<pre class='brush:shell'>#Tue Jan 21 15:14:40 CST 2014
namespaceID=1816120670 ## 文件系统的唯一标识符
cTime=0 ## namenode的创建时间，刚格式化为0，升级之后为时间戳
storageType=NAME_NODE ## 存储类型
layoutVersion=-41 ## 负的整数。描述了hdfs永久性数据结构的版本。与Hadoop的版本无关。与升级有关。
</pre></li>
<li><p>查看 datanode 下的version。<code>cat data/current/VERSION</code></p>
<pre class='brush:shell'>#Tue Jan 21 09:51:42 CST 2014
namespaceID=80003531
storageID=DS-949100596-192.168.56.12-50010-1387691685116
cTime=0
storageType=DATA_NODE
layoutVersion=-41
</pre><p>若 namespaceID 不相同，请将 datanode 中的id修改为 namenode 相同的 namespaceID。
同样的步骤修改其他的 datanode.
若是第一次format可以跳过此步骤。此步骤要注意避免如下错误(Incompatible namespaceID)：</p>
<pre class='brush:shell'>2014-01-21 15:07:54,890 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible namespaceIDs in /home/hadoop/env/data/data: namenode namespaceID = 2020545490; datanode namespaceID = 80003531
</pre></li>
</ol>
<h4>查看 NameNode 试验前正常环境状况</h4>
<ol>
<li><p>启动hdfs./bin/start-dfs.sh</p>
</li>
<li><p>jps 检查所有的进程(当前NameNode进程正常)</p>
<pre class='brush:shell'>5832 SecondaryNameNode
6293 Jps
5681 NameNode
2212 DataNode
2198 DataNode
</pre></li>
<li><p>创建测试数据</p>
<pre class='brush:shell'>$ ./bin/hadoop fs -mkdir /test
$ ./bin/hadoop fs -lsr /
drwxr-xr-x   - hadoop supergroup          0 2014-01-21 15:21 /test
[hadoop@master11 hadoop]$ ./bin/hadoop fs -put ivy.xml /test
[hadoop@master11 hadoop]$ ./bin/hadoop fs -lsr /
drwxr-xr-x   - hadoop supergroup          0 2014-01-21 15:22 /test
-rw-r--r--   2 hadoop supergroup      10525 2014-01-21 15:22 /test/ivy.xml
</pre></li>
<li><p>查看 SecondaryNameNode 文件目录</p>
<pre class='brush:shell'>watch ls ./data/snn/ 
current
image
in_use.l
</pre></li>
<li><p>namenode 对应日志</p>
<pre class='brush:shell'>2014-01-21 15:54:02,654 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.56.11
2014-01-21 15:54:02,654 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0
2014-01-21 15:54:02,655 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/home/hadoop/env/data/name/current/edits
2014-01-21 15:54:02,655 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/home/hadoop/env/data/name/current/edits
2014-01-21 15:54:02,778 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://0.0.0.0:50090/getimage?getimage=1
2014-01-21 15:54:02,781 INFO org.apache.hadoop.hdfs.server.namenode.GetImageServlet: Downloaded new fsimage with checksum: 4a75545e83f108e21ef321fb0066ede4
2014-01-21 15:54:02,781 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll FSImage from 192.168.56.11
2014-01-21 15:54:02,781 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 56
2014-01-21 15:54:02,784 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: closing edit log: position=4, editlog=/home/hadoop/env/data/name/current/edits.new
2014-01-21 15:54:02,784 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: close success: truncate to 4, editlog=/home/hadoop/env/data/name/current/edits.new
</pre></li>
<li><p>namenode 文件目录</p>
<pre class='brush:shell'>$ cd name/
$ tree
.
├── current
│   ├── edits
│   ├── fsimage
│   ├── fstime
│   └── VERSION
├── image
│   └── fsimage
├── in_use.lock
└── previous.checkpoint
├── edits
├── fsimage
├── fstime
└── VERSION
</pre></li>
</ol>
<h4>模拟 NameNode 故障</h4>
<ol>
<li>人为的杀掉 namenode 进程<pre class='brush:shell'>kill -9 6690 ## 6690 NameNode
删除 namenode 元数据
$ rm -rf ./data/name/*
删除 Secondary NameNode in_use.lock 文件 
$ rm -rf ./snn/in_use.lock
</pre></li>
</ol>
<h4>从 SecondaryNameNode 中恢复 NameNode</h4>
<ol>
<li><p>启动以 importCheckpoint 方式启动 NameNode。<code>$ ./bin/hadoop namenode -importCheckpoint</code></p>
</li>
<li><p>验证是否恢复成功</p>
<pre class='brush:shell'>## HDFS 文件系统正常
$ ./bin/hadoop fsck /
The filesystem under path '/' is HEALTHY
$ ./bin/hadoop fs -lsr /
## 元文件信息已恢复
drwxr-xr-x   - hadoop supergroup          0 2014-01-21 15:22 /test
-rw-r--r--   2 hadoop supergroup      10525 2014-01-21 15:22 /test/ivy.xml
$ tree
.
├── data
├── name(已恢复)
│   ├── current
│   │   ├── edits
│   │   ├── fsimage
│   │   ├── fstime
│   │   └── VERSION
│   ├── image
│   │   └── fsimage
│   ├── in_use.lock
│   └── previous.checkpoint
│       ├── edits
│       ├── fsimage
│       ├── fstime
│       └── VERSION
├── snn
│   ├── current
│   │   ├── edits
│   │   ├── fsimage
│   │   ├── fstime
│   │   └── VERSION
│   ├── image
│   │   └── fsimage
│   └── in_use.lock
└── tmp
9 directories, 16 files
</pre></li>
<li><p>查看恢复日志信息(截取部分信息)</p>
<pre class='brush:shell'>## copy fsimage
14/01/21 16:57:52 INFO common.Storage: Storage directory /home/hadoop/env/data/name is not formatted.
14/01/21 16:57:52 INFO common.Storage: Formatting ...
14/01/21 16:57:52 INFO common.Storage: Start loading image file /home/hadoop/env/data/snn/current/fsimage
14/01/21 16:57:52 INFO common.Storage: Number of files = 3
14/01/21 16:57:52 INFO common.Storage: Number of files under construction = 0
14/01/21 16:57:52 INFO common.Storage: Image file /home/hadoop/env/data/snn/current/fsimage of size 274 bytes loaded in 0 seconds.
##copy edits
4/01/21 16:57:52 INFO namenode.FSEditLog: Start loading edits file /home/hadoop/env/data/snn/current/edits
14/01/21 16:57:52 INFO namenode.FSEditLog: EOF of /home/hadoop/env/data/snn/current/edits, reached end of edit log Number of transactions found: 0.  Bytes read: 4
14/01/21 16:57:52 INFO namenode.FSEditLog: Start checking end of edit log (/home/hadoop/env/data/snn/current/edits) ...
14/01/21 16:57:52 INFO namenode.FSEditLog: Checked the bytes after the end of edit log (/home/hadoop/env/data/snn/current/edits):
14/01/21 16:57:52 INFO namenode.FSEditLog:   Padding position  = -1 (-1 means padding not found)
14/01/21 16:57:52 INFO namenode.FSEditLog:   Edit log length   = 4
14/01/21 16:57:52 INFO namenode.FSEditLog:   Read length       = 4
14/01/21 16:57:52 INFO namenode.FSEditLog:   Corruption length = 0
14/01/21 16:57:52 INFO namenode.FSEditLog:   Toleration length = 0 (= dfs.namenode.edits.toleration.length)
14/01/21 16:57:52 INFO namenode.FSEditLog: Summary: |---------- Read=4 ----------|-- Corrupt=0 --|-- Pad=0 --|
14/01/21 16:57:52 INFO namenode.FSEditLog: Edits file /home/hadoop/env/data/snn/current/edits of size 4 edits # 0 loaded in 0 seconds.
14/01/21 16:57:52 INFO common.Storage: Image file /home/hadoop/env/data/name/current/fsimage of size 274 bytes saved in 0 seconds.
14/01/21 16:57:54 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/home/hadoop/env/data/name/current/edits
14/01/21 16:57:54 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/home/hadoop/env/data/name/current/edits
14/01/21 16:57:54 INFO namenode.FSEditLog: Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 
## 恢复 fsimage
14/01/21 16:57:54 INFO namenode.FSNamesystem: Finished loading FSImage in 1971 msecs
14/01/21 16:57:54 INFO hdfs.StateChange: STATE* Safe mode ON
... ...
14/01/21 16:58:26 INFO hdfs.StateChange: STATE* Safe mode termination scan for invalid, over- and under-replicated blocks completed in 15 msec
14/01/21 16:58:26 INFO hdfs.StateChange: STATE* Leaving safe mode after 33 secs
## 离开安全模式 Safe mode is OFF
14/01/21 16:58:26 INFO hdfs.StateChange: STATE* Safe mode is OFF
14/01/21 16:58:26 INFO hdfs.StateChange: STATE* Network topology has 1 racks and 2 datanodes
14/01/21 16:58:26 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
</pre></li>
</ol>
</div>
  <footer>
    <p class="meta">
<span class="byline author vcard">作者 <span class="fn">kangfoo</span></span>      


<time datetime="2014-02-26T00:50:00+08:00" pubdate>2014年02月26日</time>

<span class="categories">属于 <a class="category" href="/category/hadoop/">hadoop</a>
 分类</span>


<span class="categories">被贴了 <a class="tag" href="/tag/hadoop1/">hadoop1</a>
 标签</span>
    </p>
<div class="sharing">
  
<!-- sharebar button begin -->
<div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a title="分享到豆瓣网" href="#" class="bds_douban" data-cmd="douban"></a><a title="分享到新浪微博" href="#" class="bds_tsina" data-cmd="tsina"></a><a title="分享到腾讯微博" href="#" class="bds_tqq" data-cmd="tqq"></a><a title="分享到网易微博" href="#" class="bds_t163" data-cmd="t163"></a><a title="分享到有道云笔记" href="#" class="bds_youdao" data-cmd="youdao"></a><a title="分享到Facebook" href="#" class="bds_fbook" data-cmd="fbook"></a><a title="分享到delicious" href="#" class="bds_deli" data-cmd="deli"></a><a title="分享到Twitter" href="#" class="bds_twi" data-cmd="twi"></a><a title="分享到打印" href="#" class="bds_print" data-cmd="print"></a><a title="分享到复制网址" href="#" class="bds_copy" data-cmd="copy"></a></div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["douban","tsina","tqq","t163","youdao","fbook","deli","twi","print","copy"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":false}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=86326610.js?cdnversion='+~(-new Date()/36e5)];</script>
<!-- sharebar button end -->

</div>
<p>
  <h2>相关文章</h2>
  <ul id="related-posts-list">
      <li class="post">
        <a href="/article/2014/02/hadoop-ji-jia-gan-zhi/">Hadoop 机架感知</a>
        <div class="source right"><time datetime="2014-02-26T00:52:00">2014-02-26</time></div>
      </li>
      <li class="post">
        <a href="/article/2014/02/java-jni--lian-xi/">Java JNI练习</a>
        <div class="source right"><time datetime="2014-02-26T00:55:00">2014-02-26</time></div>
      </li>
      <li class="post">
        <a href="/article/2014/02/nativehadoop--bian-yi/">Native-hadoop 编译</a>
        <div class="source right"><time datetime="2014-02-26T00:57:00">2014-02-26</time></div>
      </li>
      <li class="post">
        <a href="/article/2014/02/hadoop-c-pipes--bian-yi/">Hadoop Pipes 编译</a>
        <div class="source right"><time datetime="2014-02-26T01:01:00">2014-02-26</time></div>
      </li>
      <li class="post">
        <a href="/article/2014/02/hadoop-hdfs-1/">Hadoop 分布式文件系统</a>
        <div class="source right"><time datetime="2014-02-25T22:46:00">2014-02-25</time></div>
      </li>
  </ul>
</p>    <p class="meta">
        <a class="basic-alignment left" href="/article/2014/02/hadoop-hdfs-1/" title="上一篇: Hadoop 分布式文件系统">&laquo; Hadoop 分布式文件系统</a>
        <a class="basic-alignment right" href="/article/2014/02/hadoop-ji-jia-gan-zhi/" title="下一篇: Hadoop 机架感知">Hadoop 机架感知 &raquo;</a>
    </p>
  </footer>
</article>
  <section>
    <h1>评论</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">
<section>
  <h1>近期文章</h1>
  <ul id="recent_posts">
  
  
      <li class="post">
        <a href="/article/2014/03/hadoop--xue-xi-can-kao-bo-ke-hui-zong/">Hadoop MapReduce 学习参考博客汇总</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-pipes--streaming/">Hadoop Pipes & Streaming</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-sort/">Hadoop MapReduce Sort</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-join/">Hadoop MapReduce Join</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce--ji-shu-qi/">Hadoop MapReduce 计数器</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-recordreader-zu-jian/">Hadoop MapReduce RecordReader 组件</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-partitioner--zu-jian/">Hadoop MapReduce Partitioner 组件</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce-combiner--zu-jian/">Hadoop MapReduce Combiner 组件</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce--lei-xing-yu-ge-shi/">Hadoop MapReduce 类型与格式</a>
      </li>
      <li class="post">
        <a href="/article/2014/03/hadoop-mapreduce--gong-zuo-ji-zhi/">Hadoop MapReduce 工作机制</a>
      </li>
  </ul>
</section>
<section>
  <h2>近期评论</h2>
 <script language="JavaScript">
  <!--
	var is_https = ('https:' == document.location.protocol);
	var rcw_script_src = (is_https ? 'https:' : 'http:') + '//kangaroo.disqus.com/recent_comments_widget.js?num_items=5&excerpt_length=100&hide_avatars=' + (is_https ? '1' : '0&avatar_size=32');
	var rcw_script = '<scr' + 'ipt type="text/javascript" src="' + rcw_script_src + '"></scr' + 'ipt>';
	document.writeln(rcw_script);
  //-->
  </script>
</section>
</aside>
    </div>
  </div>
  <footer role="contentinfo"><p>
  版权所有 &copy; 2014 - kangfoo -
  <span class="credit">Powered by <a href="http://www.opoopress.com/">OpooPress</a></span>
 
  <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1000232528'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s22.cnzz.com/z_stat.php%3Fid%3D1000232528%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</p>
</footer>
<script type="text/javascript" src="/javascripts/opoopress.min.js"></script>
<script language="JavaScript">
<!--
    window.OpooPress = new OpooPressApp({siteUrl:'http://kangfoo.u.qiniudn.com/',rootUrl:'',pageUrl:'/article/2014/02/shi-yong-secondenamenode-hui-fu-namenode/',title:'模拟使用 SecondaryNameNode 恢复 NameNode',refreshRelativeTimes:true,verbose:true},{});
    OpooPress.init();

    var disqus_shortname = 'kangaroo';
    
    // var disqus_developer = 1;
    var disqus_identifier = 'http://kangfoo.u.qiniudn.com//article/2014/02/shi-yong-secondenamenode-hui-fu-namenode/';
    var disqus_url = 'http://kangfoo.u.qiniudn.com//article/2014/02/shi-yong-secondenamenode-hui-fu-namenode/';
    var disqus_title = '模拟使用 SecondaryNameNode 恢复 NameNode';
    //var disqus_category_id = '';
    OpooPress.showDisqusWidgets();
//-->
</script>
<!-- START: Syntax Highlighter ComPress -->
<script type="text/javascript" src="/plugins/syntax-highlighter/scripts/shCore.js"></script>
<script type="text/javascript" src="/plugins/syntax-highlighter/scripts/shAutoloader.js"></script>
<script type="text/javascript">
    SyntaxHighlighter.autoloader(
        'applescript			/plugins/syntax-highlighter/scripts/shBrushAppleScript.js',
        'actionscript3 as3		/plugins/syntax-highlighter/scripts/shBrushAS3.js',
        'bash shell				/plugins/syntax-highlighter/scripts/shBrushBash.js',
        'coldfusion cf			/plugins/syntax-highlighter/scripts/shBrushColdFusion.js',
        'cpp c					/plugins/syntax-highlighter/scripts/shBrushCpp.js',
        'c# c-sharp csharp		/plugins/syntax-highlighter/scripts/shBrushCSharp.js',
        'css					/plugins/syntax-highlighter/scripts/shBrushCss.js',
        'delphi pascal pas		/plugins/syntax-highlighter/scripts/shBrushDelphi.js',
        'diff patch			    /plugins/syntax-highlighter/scripts/shBrushDiff.js',
        'erl erlang				/plugins/syntax-highlighter/scripts/shBrushErlang.js',
        'groovy					/plugins/syntax-highlighter/scripts/shBrushGroovy.js',
        'java					/plugins/syntax-highlighter/scripts/shBrushJava.js',
        'jfx javafx				/plugins/syntax-highlighter/scripts/shBrushJavaFX.js',
        'js jscript javascript	/plugins/syntax-highlighter/scripts/shBrushJScript.js',
        'perl pl				/plugins/syntax-highlighter/scripts/shBrushPerl.js',
        'php					/plugins/syntax-highlighter/scripts/shBrushPhp.js',
        'text plain				/plugins/syntax-highlighter/scripts/shBrushPlain.js',
        'powershell ps          /plugins/syntax-highlighter/scripts/shBrushPowerShell.js',
        'py python				/plugins/syntax-highlighter/scripts/shBrushPython.js',
        'ruby rails ror rb		/plugins/syntax-highlighter/scripts/shBrushRuby.js',
        'sass scss              /plugins/syntax-highlighter/scripts/shBrushSass.js',
        'scala					/plugins/syntax-highlighter/scripts/shBrushScala.js',
        'sql					/plugins/syntax-highlighter/scripts/shBrushSql.js',
        'vb vbnet				/plugins/syntax-highlighter/scripts/shBrushVb.js',
        'xml xhtml xslt html	/plugins/syntax-highlighter/scripts/shBrushXml.js'
    );
    SyntaxHighlighter.defaults['auto-links'] = false;                 
    SyntaxHighlighter.defaults['toolbar'] = false;     
    SyntaxHighlighter.defaults['tab-size'] = 4;
    SyntaxHighlighter.all();
</script>
<!-- END: Syntax Highlighter ComPress -->
</body>
</html>

